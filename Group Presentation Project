{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["bcRHD-ZPDieW"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TulPKLbLsOmx"},"source":["# **Big Data in Finance II Group Assignment**"]},{"cell_type":"markdown","source":["**Group 7 Members:**\n","- 01705898 Gus Lee  \n","- 02324852 Baiyu Lu\n","- 02333891 Dmitry Tertychnyy \n","- 02283242 Patrik Kovac\n"],"metadata":{"id":"Cs7eRMFqPX4Y"}},{"cell_type":"markdown","source":["# Library Import"],"metadata":{"id":"BKR5sW8Tyaja"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from datetime import datetime\n","from dateutil.relativedelta import relativedelta\n","import matplotlib.dates as mdates\n","\n","# for Google Colab\n","from google.colab import drive \n","drive.mount('/content/drive')\n","\n","# for GBM\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# for RandomForest\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# for OLS \n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKXDqQewzXWx","executionInfo":{"status":"ok","timestamp":1686145201454,"user_tz":-120,"elapsed":3847,"user":{"displayName":"Dmitry Tertychnyy","userId":"01455676677788782180"}},"outputId":"e1204e2f-ad79-46eb-941c-1252bcea9ebd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Data Handling"],"metadata":{"id":"2GTKq01mwI37"}},{"cell_type":"markdown","source":["### **Implementation**\n","In this section we undertake the task of building our dataset. We read the data from pickle and save it as a pandas dataframe. We then remove some of the variables and separate the data into our dependent and independent variables. "],"metadata":{"id":"zgJvlzVMCnW_"}},{"cell_type":"code","source":["# Import data\n","panel = pd.read_pickle(\"/content/drive/MyDrive/Big_Data_Fin2/Data/returns_chars_panel.pkl\") # stock characteristics\n","macro = pd.read_pickle(\"/content/drive/MyDrive/Big_Data_Fin2/Data/macro_timeseries.pkl\")    # macro indices"],"metadata":{"id":"SB42xsc0y_Qu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# In the paper, variables 'crsp_spvw' , 'dfr', 'infl' are not used so we drop them.\n","# We keep the same dataset as from the coursework.\n","macro.drop(columns=['crsp_spvw','dfr','infl'], inplace=True)\n","macro_pred = macro.columns.to_list()\n","macro_pred.remove('date')\n","\n","# Combine micro and macro data\n","df = pd.merge(panel, macro, on='date', how='left', suffixes=['','_macro'])\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vskwp7c9zBj4","executionInfo":{"status":"ok","timestamp":1686145240691,"user_tz":-120,"elapsed":7240,"user":{"displayName":"Dmitry Tertychnyy","userId":"01455676677788782180"}},"outputId":"7e4d227d-6037-4e27-c788-d40c50b83239"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3739449, 107)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# to save the storing space\n","del panel, macro"],"metadata":{"id":"f069roiWzBnz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# features (X) + targets (Y)\n","# Note: for X, use everything except return info, IDs and excess macro variables\n","X = df.drop(columns=['ret', 'excess_ret', 'rfree', 'permno', 'date']) \n","y = df['excess_ret']"],"metadata":{"id":"YwO-izomzBqq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"lc_IWhEvRfTv"}},{"cell_type":"markdown","source":["## **custom_ts_split**\n","\n","This function aims to create a generator object of date which specify the times at which we will be splitting our values into train, validate and test. This is very similar to the work of Gu, Kelly and Xiu (2019). This object will then be passed to the dataframe date column to split our dataframes containing the dependent and independent values into train, validate and test. The ranges are generated by adding the sizes of the training, validation, and test sets to the start year, and then advancing the start year by the step size in each iteration. \n"],"metadata":{"id":"bcRHD-ZPDieW"}},{"cell_type":"code","source":["def custom_ts_split(start_year, end_year, train_size, val_size, test_size, step):\n","    \n","    # Convert string and integer to datetime format\n","    start_year_dt = datetime.strptime(start_year, '%Y-%m')\n","    end_year_dt = datetime.strptime(end_year, '%Y-%m')\n","    train_size_dt = relativedelta(years=train_size)\n","    val_size_dt = relativedelta(years=val_size)\n","    test_size_dt = relativedelta(years=test_size)\n","    step_dt = relativedelta(years=step)\n","    \n","    current_year = start_year_dt\n","    \n","    while current_year + train_size_dt + val_size_dt + test_size_dt <= end_year_dt + relativedelta(years=1):\n","        \n","        # Get train start and end date\n","        train_start = start_year_dt\n","        train_end = current_year + train_size_dt\n","        \n","        # Get validation start and end date\n","        val_start = train_end\n","        val_end = val_start + val_size_dt\n","        \n","        # Get test start and end date\n","        test_start = val_end\n","        test_end = test_start + test_size_dt\n","        if test_end < end_year_dt:\n","            test_end = test_end\n","        else:\n","            test_end = end_year_dt\n","\n","        yield train_end, val_end, test_end\n","\n","        current_year += step_dt"],"metadata":{"id":"AhCCrdprRiO-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **get_tscv_plot**\n","\n","The function get_tscv_plot aims to provide visualization of the train cross-validate and test folds. It utilises a similar logic as custom_ts_split to produce the time periods, and it accepts the same inputs. It constructs a horizontal bar plot displaying the train, validation, and test splits for each fold.\n","\n"],"metadata":{"id":"Snep_pOrGe46"}},{"cell_type":"code","source":["def get_tscv_plot(start_year, end_year, train_size, val_size, test_size, step):\n","    \n","    # Convert str and int into a datetime compatible format\n","    start_year_dt = datetime.strptime(start_year, '%Y-%m')\n","    end_year_dt = datetime.strptime(end_year, '%Y-%m')\n","    train_size_dt = relativedelta(years=train_size)\n","    val_size_dt = relativedelta(years=val_size)\n","    test_size_dt = relativedelta(years=test_size)\n","    step_dt = relativedelta(years=step)\n","    \n","    # Get all the date indexes for all the folds into a dictionary\n","    folds = []\n","    current_year = start_year_dt\n","    \n","    while current_year + train_size_dt + val_size_dt + test_size_dt <= end_year_dt + relativedelta(years=1):\n","        \n","        train_start = start_year_dt\n","        train_end = current_year + train_size_dt\n","        \n","        val_start = train_end\n","        val_end = val_start + val_size_dt\n","        \n","        test_start = val_end\n","        test_end = test_start + test_size_dt\n","        if test_end < end_year_dt:\n","            test_end = test_end\n","        else:\n","            test_end = end_year_dt\n","\n","        date_info = {'train_start':start_year_dt, 'train_end':train_end, 'val_start':val_start, 'val_end':val_end, \n","                     'test_start':test_start, 'test_end':test_end}\n","        folds.append(date_info)\n","        current_year += step_dt\n","    \n","    # Set up the plot\n","    fig, ax = plt.subplots(figsize=(12,6))\n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n","\n","    # Set the y-axis ticks and labels\n","    y_ticks = range(1, len(folds) + 1)\n","    y_labels = [f'Fold {i}' for i in y_ticks[::-1]]\n","    ax.set_yticks(y_ticks)\n","    ax.set_yticklabels(y_labels)\n","\n","    # Plot the bars for each fold\n","    i = 1\n","    for fold in folds[::-1]:\n","        train_start = fold['train_start']\n","        train_end = fold['train_end']\n","        val_start = fold['val_start']\n","        val_end = fold['val_end']\n","        test_start = fold['test_start']\n","        test_end = fold['test_end']\n","\n","        ax.barh(i, train_end - train_start, left=train_start, height=0.5, color='blue', label='Train')\n","        ax.barh(i, val_end - val_start, left=val_start, height=0.5, color='orange', label='Validation')\n","        ax.barh(i, test_end - test_start, left=test_start, height=0.5, color='red', label='Test')\n","        i += 1\n","\n","    # Set the x-axis limits and labels\n","    ax.set_xlim(folds[0]['train_start'].replace(month=1), folds[-1]['test_end'].replace(month=1))\n","    ax.set_xlabel('Year')\n","\n","    # Add a legend\n","    handles = [plt.Rectangle((0, 0), 1, 1, color='blue'),\n","               plt.Rectangle((0, 0), 1, 1, color='orange'),\n","               plt.Rectangle((0, 0), 1, 1, color='red')]\n","    labels = ['Train', 'Validation', 'Test']\n","    ax.legend(handles, labels, loc='upper right')\n","\n","    # Show the plot\n","    plt.show()\n","    \n","    return None"],"metadata":{"id":"RozNz-cyRjF6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **normalize**\n","\n","The function normalize aims to take any series of values and return the series as a normalized decimal. It works by taking a series of values and then takes thier sum. Once we have the sum every value in the series divided by total sum to gain the decimal. Since this is done using list comprehension a list is returned. \n"],"metadata":{"id":"e2Me5yFmIMKF"}},{"cell_type":"code","source":["def normalize(values):\n","    \n","    total = sum(values)\n","    normalized_values = [x / total for x in values]\n","    \n","    return normalized_values"],"metadata":{"id":"TU6RfrgaRoNy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **get_var_imp_plot**\n","\n","Lastly, get_var_imp_plot is just a plotting function which takes a variaety of labels and values and then plots them in decreasing order using a horizontal bar graph. \n"],"metadata":{"id":"eyf7AA_WIRaE"}},{"cell_type":"code","source":["def get_var_imp_plot(var_imp_df, model): \n","  \n","  # Sort the variable importance in ascending order\n","  sorted_var_imp = var_imp_df.sort_values('Variable Importance', ascending=True)\n","\n","  # Plot the horizontal bar plot\n","  sorted_var_imp.plot.barh(x='Predictor', y='Variable Importance', legend=False)\n","\n","  # Set the plot title and axis labels\n","  plt.title(f'{model}')\n","  plt.ylabel('Predictor')\n","\n","  # Show the plot\n","  plt.show()"],"metadata":{"id":"ut5sTSbuRp0Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Rolling Window Settings**\n"],"metadata":{"id":"aT_7AvI_Rv0g"}},{"cell_type":"code","source":["start_year = '1957-03'\n","end_year = '2016-12'\n","train_size = 30        # Number of years in the training set\n","val_size = 20          # Number of years in the validation set\n","test_size = 2          # Number of years in the test set\n","step = 2               # Size increase in training set (in years) from one fold to the next"],"metadata":{"id":"Nk81CyndRvEm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_tscv_plot(start_year, end_year, train_size, val_size, test_size, step)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"-o7_G-U11PmN","executionInfo":{"status":"ok","timestamp":1686143873755,"user_tz":-120,"elapsed":323,"user":{"displayName":"Dmitry Tertychnyy","userId":"01455676677788782180"}},"outputId":"924d23b7-eff1-47b9-e22c-2f3902d19dfa"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### **Implementation**\n","We elaborate on the work of Gu, Kelly and Xiu (2019) by building up three models that try to predict returns. We first use a simple OLS regression with two sets of features. We then employ a gradient boosted machine model and finally a random forest framework. We then compare the performances with each other and the original study as well.\n","\n","We follow the paper to form a dataset that contains montly stock returns from 1957 to 2016. There are data 94 charateristic features of the stock plus 8 macroeconomic predictors. The whole dataset is of the shape (3739449, 107).\n","\n","We configure our parameters using grid search \n","\n","**Tuning for OLS:**\n",">- f: S → L\n","- x ∈ S\n","- X_all = {x1, x2, ..., xn} as the set of all variables\n","- X_top = {x'_1, x'_2, ..., x'_10} as the set of the 10 most important variables\n","\n",">Model 1\n","  - L_all = *L*(**y**, *h*(X_all))\n","\n",">Model 2 \n","  - L_top = *L*(**y**, *h*(X_top))\n","\n","**Tuning for GBM:**\n",">params = {\n","    'n_estimators': [50, 100, 150, 200],\n","    'max_depth': [1,3,5,9],\n","    'learning_rate': [0.01, 0.1, 0.001],\n","    #'loss': ['reg:squarederror'] #objective maybe if it does't work?\n","}\n","\n",">**Tuning for RF:**\n",">\n","\n"],"metadata":{"id":"uqb8-HddP5Q3"}},{"cell_type":"markdown","source":["\n","### **Check for specific rolling dates**\n"],"metadata":{"id":"Oz9aEUSLSyiX"}},{"cell_type":"code","source":["for i, (train_end, val_end, test_end) in enumerate(custom_ts_split(start_year, end_year, train_size, val_size, test_size, step)):\n","    print(f\"Fold {i+1}:\")\n","    \n","    #train_set = your_data[train_index]\n","    print(f\"Train end: index={train_end}\")\n","    \n","    #val_set = your_data[val_index]\n","    print(f\"Validation end:  index={val_end}\")\n","    \n","    #test_set = your_data[test_index]\n","    print(f\"Test end:  index={test_end}\\n\")"],"metadata":{"id":"nUBUeji9CiFb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686143875016,"user_tz":-120,"elapsed":2,"user":{"displayName":"Dmitry Tertychnyy","userId":"01455676677788782180"}},"outputId":"49f6a571-d67c-4070-c5e7-1e932c26e826"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1:\n","Train end: index=1987-03-01 00:00:00\n","Validation end:  index=2007-03-01 00:00:00\n","Test end:  index=2009-03-01 00:00:00\n","\n","Fold 2:\n","Train end: index=1989-03-01 00:00:00\n","Validation end:  index=2009-03-01 00:00:00\n","Test end:  index=2011-03-01 00:00:00\n","\n","Fold 3:\n","Train end: index=1991-03-01 00:00:00\n","Validation end:  index=2011-03-01 00:00:00\n","Test end:  index=2013-03-01 00:00:00\n","\n","Fold 4:\n","Train end: index=1993-03-01 00:00:00\n","Validation end:  index=2013-03-01 00:00:00\n","Test end:  index=2015-03-01 00:00:00\n","\n","Fold 5:\n","Train end: index=1995-03-01 00:00:00\n","Validation end:  index=2015-03-01 00:00:00\n","Test end:  index=2016-12-01 00:00:00\n","\n"]}]},{"cell_type":"markdown","source":["# Model Fitting "],"metadata":{"id":"iezpfczfF7LF"}},{"cell_type":"markdown","source":["### **(OLS - All Features)**\n"],"metadata":{"id":"1bGY_OE_Na-L"}},{"cell_type":"markdown","source":["In this section we will implement a standard OLS regression with all the features. *{Add the R-sqared here and comment on it}*. In literature the rationale behind using OLS is to have a baseline prediction model we are trying to beat. As such we have decided to use the OLS as a baseline. We utilized two versions of the OLS, one with all the features and one with only 10 of the features. "],"metadata":{"id":"RxJDM3MqMs30"}},{"cell_type":"code","source":["# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create an OLS model\n","model = LinearRegression()\n","\n","# Fit the model\n","model.fit(X_train, y_train)\n","\n","# Predict the target variable for the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate the accuracy (optional, as we're dealing with regression, not classification)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"R-squared: {r2}\")"],"metadata":{"id":"c2EaNB_PHu_r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **OLS - 10 Features Only**"],"metadata":{"id":"SiybMvNADmkx"}},{"cell_type":"markdown","source":["In this section we will implement a standard OLS regression with 10 of the features, which were the top 10 most important features in the ANN model. *{Add the R-sqared here and comment on it}*. The OLS model with less features performed better than the one with more which suggests that a lot of the fetaures are just noise when predicting using a linear estimator / model. {Comment on the comparison of the  p values as well to see if they are significantly different}"],"metadata":{"id":"cpAwhIToBK6M"}},{"cell_type":"code","source":["# Select variables for the model\n","selected_vars = ['maxret', 'std_turn', 'ill', 'lev', 'chcsho', 'operprof', 'cfp_ia', 'turn', 'sp', 'orgcap']\n","X = df[selected_vars]\n","y = df['excess_ret']\n","\n","# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create an OLS model\n","model = LinearRegression()\n","\n","# Fit the model\n","model.fit(X_train, y_train)\n","\n","# Predict the target variable for the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate the accuracy (optional, as we're dealing with regression, not classification)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"R-squared: {r2}\")"],"metadata":{"id":"-WxJIM1UDrrJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **GBM**\n","In this section we employ a more advanced ML technique and use XG Boost to predict the return. XG boost is a Gradient Boosting Model that is a ensable learning method. This means that it addively creates weak learners and then adds them together to create a model with greate predictive accuracy. We use grid search and cross validation to find the optimal setup for our \n"],"metadata":{"id":"1aD71N7KxZNX"}},{"cell_type":"code","source":["def are_all_columns_numeric(df):\n","    numeric_cols = df.select_dtypes(include=[float, int]).columns\n","    return len(numeric_cols) == len(df.columns)\n"],"metadata":{"id":"K43ZAGTtS1wG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if are_all_columns_numeric(df):\n","    print(\"All columns are numeric\")\n","else:\n","    print(\"Not all columns are numeric\")"],"metadata":{"id":"3pRgye8oWRKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_year = '1957-03'\n","end_year = '2016-12'\n","train_size = 30        # Number of years in the training set\n","val_size = 20          # Number of years in the validation set\n","test_size = 2          # Number of years in the test set\n","step = 2\n","\n","import pandas as pd\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","# Load your data\n","# df = pd.read_csv('your_data.csv')\n","# Assume you already have X (features) and y (labels)\n","\n","# Set up our parameters for GBM\n","params = {\n","    'n_estimators': [50, 100, 150, 200],\n","    'max_depth': [1,3,5,9],\n","    'learning_rate': [0.01, 0.1, 0.5],\n","    #'loss': ['reg:squarederror'] #objective maybe if it does't work?\n","}\n","\n","# Instantiate the classifier \n","gbm_reg = GradientBoostingRegressor()\n","\n","# Initialize accuracy list\n","accuracies = []\n","\n","# Convert 'date' column to datetime if it's not already\n","try:\n","  df['date'] = pd.to_datetime(df['date'])\n","except:\n","  pass\n","\n","# Define custom time series splitter that yields indices\n","def custom_ts_split_indices(df, date_col, train_end, test_start, test_end):\n","    train_indices = df[df[date_col] < train_end].index\n","    test_indices = df[(df[date_col] >= test_start) & (df[date_col] < test_end)].index\n","    return [(train_indices, test_indices)]\n","\n","# Using your custom time series split function\n","for train_end, val_end, test_end in custom_ts_split(start_year=start_year, end_year=end_year, train_size=train_size, val_size=val_size, test_size=test_size, step=step):\n","    \n","    # For simplicity, we will just use the training set and the test set. \n","    # You can utilize the validation set for hyperparameter tuning or early stopping.\n","    \n","    # Select data for the training and test sets\n","    train_data = df[df['date'] < train_end]\n","    test_data = df[(df['date'] >= test_start) & (df['date'] < test_end)]\n","    \n","    # Separate features and labels\n","    X_train, y_train = train_data.drop('label', axis=1), train_data['label']\n","    X_test, y_test = test_data.drop('label', axis=1), test_data['label']\n","    \n","    # Set up the grid search with cross-validation\n","    gbm_cv = GridSearchCV(gbm_reg, params, cv=custom_ts_split_indices(df, 'date', train_end, val_end, test_end))\n","    \n","    # Fit the model and find optimal hyperparameters\n","    gbm_cv.fit(X_train, y_train)\n","    \n","    # Make predictions using the model with the best found hyperparameters\n","    preds = gbm_cv.predict(X_test)\n","    \n","    # Evaluate accuracy and append to accuracy list\n","    acc = accuracy_score(y_test, preds)\n","    accuracies.append(acc)\n","\n","# Calculate mean accuracy over all splits\n","mean_acc = sum(accuracies) / len(accuracies)\n","print(f\"Mean accuracy: {mean_acc}\")\n"],"metadata":{"id":"GFG5cEWvbDGI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **RandomForest**\n","\n","---\n","\n"],"metadata":{"id":"A-JirWfNUZhW"}},{"cell_type":"code","source":["# Split data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create a random forest model\n","model = RandomForestRegressor()\n","\n","# Fit the model\n","model.fit(X_train, y_train)\n","\n","# Predict the target variable for the test set\n","y_pred = model.predict(X_test)\n","\n","# Calculate the accuracy (optional, as we're dealing with regression, not classification)\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy}\")\n","\n","# Get feature importances\n","importances = model.feature_importances_\n","feature_names = X.columns.tolist()\n","feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n","top_10_features = feature_importances.nlargest(10, 'Importance')\n","\n","print(\"Top 10 Features:\")\n","print(top_10_features)"],"metadata":{"id":"FBV6ySoYcCbY"},"execution_count":null,"outputs":[]}]}